{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "PatientID                    0\n",
      "Age                          0\n",
      "Gender                       0\n",
      "Ethnicity                    0\n",
      "EducationLevel               0\n",
      "BMI                          0\n",
      "Smoking                      0\n",
      "AlcoholConsumption           0\n",
      "PhysicalActivity             0\n",
      "DietQuality                  0\n",
      "SleepQuality                 0\n",
      "FamilyHistoryAlzheimers      0\n",
      "CardiovascularDisease        0\n",
      "Diabetes                     0\n",
      "Depression                   0\n",
      "HeadInjury                   0\n",
      "Hypertension                 0\n",
      "SystolicBP                   0\n",
      "DiastolicBP                  0\n",
      "CholesterolTotal             0\n",
      "CholesterolLDL               0\n",
      "CholesterolHDL               0\n",
      "CholesterolTriglycerides     0\n",
      "MMSE                         0\n",
      "FunctionalAssessment         0\n",
      "MemoryComplaints             0\n",
      "BehavioralProblems           0\n",
      "ADL                          0\n",
      "Confusion                    0\n",
      "Disorientation               0\n",
      "PersonalityChanges           0\n",
      "DifficultyCompletingTasks    0\n",
      "Forgetfulness                0\n",
      "Diagnosis                    0\n",
      "DoctorInCharge               0\n",
      "dtype: int64\n",
      "\n",
      "Distribución original de clases:\n",
      "Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtener un set de datos.\n",
    "df = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "\n",
    "# 2. Buscar valores vacios\n",
    "print(\"Missing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# 3. Eliminar columnas que no agrega valor al entrenamiento\n",
    "df = df.drop('PatientID', axis=1)\n",
    "df = df.drop('DoctorInCharge', axis=1)\n",
    "\n",
    "print(\"\\nDistribución original de clases:\")\n",
    "print(df['Diagnosis'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las columnas por normalizar\n",
    "numerical_cols = [\"Age\", \"BMI\", \"AlcoholConsumption\", \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\", \"SystolicBP\", \"DiastolicBP\", \"CholesterolTotal\", \"CholesterolLDL\", \"CholesterolHDL\", \"CholesterolTriglycerides\", \"MMSE\", \"FunctionalAssessment\", \"ADL\"]\n",
    "\n",
    "# Guardar las columnas numéricas\n",
    "categorical_cols = [\"Gender\", \"Ethnicity\", \"EducationLevel\", \"Smoking\", \"FamilyHistoryAlzheimers\", \"CardiovascularDisease\", \"Diabetes\", \"Depression\", \"HeadInjury\", \"Hypertension\", \"MemoryComplaints\", \"BehavioralProblems\", \"Confusion\", \"Disorientation\", \"PersonalityChanges\", \"DifficultyCompletingTasks\", \"Forgetfulness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Separar features y target\n",
    "X = df.drop('Diagnosis', axis=1)\n",
    "y = df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dividir en train y test con un split 80 - 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aplicar las técnicas de escalamiento y transformación de datos\n",
    "# Transformar datos categóricos mediante One Hot Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Escalamiento de datos numéricos mediante StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aplicar las técnicas de escalamiento y transformación de datos\n",
    "# Transformar datos categóricos mediante One Hot Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Escalamiento de datos numéricos mediante StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Obtener nombres de features\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Crear DataFrames para datos categóricos transformados\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat_encoded, columns=encoded_feature_names)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Crear DataFrames para datos numéricos transformados\n",
    "X_train_num_df = pd.DataFrame(X_train_num_scaled, columns=numerical_cols)\n",
    "X_test_num_df = pd.DataFrame(X_test_num_scaled, columns=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Combinar datos categóricos y numéricos\n",
    "X_train_processed = pd.concat([X_train_num_df, X_train_cat_df], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_df, X_test_cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Transformar target a valor numerico mediante LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,           \n",
    "    max_depth=13,              \n",
    "    min_samples_split=5,        \n",
    "    min_samples_leaf=3,         \n",
    "    max_features=None,        \n",
    "    bootstrap=True,           \n",
    "    criterion='entropy',       \n",
    "    class_weight='balanced',   \n",
    "    random_state=42,\n",
    "    n_jobs=-1                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_processed)\n",
    "\n",
    "classes_x = y_pred.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Features:\n",
      "                      Importance\n",
      "FunctionalAssessment    0.191411\n",
      "MMSE                    0.185176\n",
      "ADL                     0.184381\n",
      "MemoryComplaints_1      0.077988\n",
      "BehavioralProblems_0    0.072829\n",
      "MemoryComplaints_0      0.065816\n",
      "BehavioralProblems_1    0.047766\n",
      "DietQuality             0.018388\n",
      "CholesterolHDL          0.015849\n",
      "Age                     0.015274\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    rf_model.feature_importances_,\n",
    "    index=X_train_processed.columns,\n",
    "    columns=['Importance']\n",
    ").sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importances.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          label neg   label pos\n",
      "pred neg     270          13\n",
      "pred pos     7          140\n",
      "Precision: 0.9523809523809523\n",
      "Recall: 0.9150326797385621\n",
      "F1: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(classes_x)):\n",
    "  if classes_x[i] == 1:\n",
    "    if y_test_encoded[i] == 1:\n",
    "      TP = TP + 1\n",
    "    else :\n",
    "      FP = FP + 1\n",
    "  else:\n",
    "    if y_test_encoded[i] == 0:\n",
    "      TN = TN + 1\n",
    "    else :\n",
    "      FN = FN + 1\n",
    "\n",
    "print('         ', 'label neg ', ' label pos')\n",
    "print('pred neg    ', TN, \"        \", FN)\n",
    "print('pred pos    ', FP, \"        \", TP)\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2*precision*recall / (precision + recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f8dd9a2b65164a0dd37b4e5739f150314b1e17efbbfa1422ea4f2e7b18b306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
