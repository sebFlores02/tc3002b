{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "PatientID                    0\n",
      "Age                          0\n",
      "Gender                       0\n",
      "Ethnicity                    0\n",
      "EducationLevel               0\n",
      "BMI                          0\n",
      "Smoking                      0\n",
      "AlcoholConsumption           0\n",
      "PhysicalActivity             0\n",
      "DietQuality                  0\n",
      "SleepQuality                 0\n",
      "FamilyHistoryAlzheimers      0\n",
      "CardiovascularDisease        0\n",
      "Diabetes                     0\n",
      "Depression                   0\n",
      "HeadInjury                   0\n",
      "Hypertension                 0\n",
      "SystolicBP                   0\n",
      "DiastolicBP                  0\n",
      "CholesterolTotal             0\n",
      "CholesterolLDL               0\n",
      "CholesterolHDL               0\n",
      "CholesterolTriglycerides     0\n",
      "MMSE                         0\n",
      "FunctionalAssessment         0\n",
      "MemoryComplaints             0\n",
      "BehavioralProblems           0\n",
      "ADL                          0\n",
      "Confusion                    0\n",
      "Disorientation               0\n",
      "PersonalityChanges           0\n",
      "DifficultyCompletingTasks    0\n",
      "Forgetfulness                0\n",
      "Diagnosis                    0\n",
      "DoctorInCharge               0\n",
      "dtype: int64\n",
      "\n",
      "Distribución original de clases:\n",
      "Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtener un set de datos.\n",
    "df = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "\n",
    "# 2. Buscar valores vacios\n",
    "print(\"Missing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# 3. Eliminar columnas que no agrega valor al entrenamiento\n",
    "df = df.drop('PatientID', axis=1)\n",
    "df = df.drop('DoctorInCharge', axis=1)\n",
    "\n",
    "print(\"\\nDistribución original de clases:\")\n",
    "print(df['Diagnosis'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las columnas por normalizar\n",
    "numerical_cols = [\"Age\", \"BMI\", \"AlcoholConsumption\", \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\", \"SystolicBP\", \"DiastolicBP\", \"CholesterolTotal\", \"CholesterolLDL\", \"CholesterolHDL\", \"CholesterolTriglycerides\", \"MMSE\", \"FunctionalAssessment\", \"ADL\"]\n",
    "\n",
    "# Guardar las columnas numéricas\n",
    "categorical_cols = [\"Gender\", \"Ethnicity\", \"EducationLevel\", \"Smoking\", \"FamilyHistoryAlzheimers\", \"CardiovascularDisease\", \"Diabetes\", \"Depression\", \"HeadInjury\", \"Hypertension\", \"MemoryComplaints\", \"BehavioralProblems\", \"Confusion\", \"Disorientation\", \"PersonalityChanges\", \"DifficultyCompletingTasks\", \"Forgetfulness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Separar features y target\n",
    "X = df.drop('Diagnosis', axis=1)\n",
    "y = df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dividir en train y test con un split 80 - 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aplicar las técnicas de escalamiento y transformación de datos\n",
    "# Transformar datos categóricos mediante One Hot Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Escalamiento de datos numéricos mediante StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aplicar las técnicas de escalamiento y transformación de datos\n",
    "# Transformar datos categóricos mediante One Hot Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Escalamiento de datos numéricos mediante StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Obtener nombres de features\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Crear DataFrames para datos categóricos transformados\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat_encoded, columns=encoded_feature_names)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Crear DataFrames para datos numéricos transformados\n",
    "X_train_num_df = pd.DataFrame(X_train_num_scaled, columns=numerical_cols)\n",
    "X_test_num_df = pd.DataFrame(X_test_num_scaled, columns=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Combinar datos categóricos y numéricos\n",
    "X_train_processed = pd.concat([X_train_num_df, X_train_cat_df], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_df, X_test_cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Transformar target a valor numerico mediante LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_gru(X):\n",
    "    return X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "X_train_gru = prepare_data_for_gru(X_train_resampled)\n",
    "X_test_gru = prepare_data_for_gru(X_test_processed)\n",
    "\n",
    "def l2_svm_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_true = 2.0 * y_true - 1.0\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(tf.maximum(0., 1. - y_true * y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianflores/miniconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(64, input_shape=(X_train_resampled.shape[1], 1), return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m12,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,929</span> (50.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,929\u001b[0m (50.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,929</span> (50.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,929\u001b[0m (50.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=l2_svm_loss,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5722 - loss: 0.9831 - val_accuracy: 0.0000e+00 - val_loss: 1.4666\n",
      "Epoch 2/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5867 - loss: 0.9715 - val_accuracy: 0.0000e+00 - val_loss: 1.4070\n",
      "Epoch 3/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5805 - loss: 0.9764 - val_accuracy: 0.0000e+00 - val_loss: 1.4686\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6016 - loss: 0.9581 - val_accuracy: 0.0000e+00 - val_loss: 1.3365\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6035 - loss: 0.9613 - val_accuracy: 0.0000e+00 - val_loss: 1.3022\n",
      "Epoch 6/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5761 - loss: 0.9788 - val_accuracy: 0.0000e+00 - val_loss: 1.5231\n",
      "Epoch 7/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5849 - loss: 0.9728 - val_accuracy: 0.0000e+00 - val_loss: 1.4647\n",
      "Epoch 8/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6009 - loss: 0.9616 - val_accuracy: 0.0000e+00 - val_loss: 1.3691\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5702 - loss: 0.9828 - val_accuracy: 0.0000e+00 - val_loss: 1.4843\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5988 - loss: 0.9596 - val_accuracy: 0.0000e+00 - val_loss: 1.2721\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5838 - loss: 0.9742 - val_accuracy: 0.0000e+00 - val_loss: 1.3403\n",
      "Epoch 12/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5818 - loss: 0.9744 - val_accuracy: 0.0000e+00 - val_loss: 1.4283\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5884 - loss: 0.9704 - val_accuracy: 0.0000e+00 - val_loss: 1.3774\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5925 - loss: 0.9647 - val_accuracy: 0.0000e+00 - val_loss: 1.4349\n",
      "Epoch 15/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5853 - loss: 0.9750 - val_accuracy: 0.0000e+00 - val_loss: 1.3845\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5780 - loss: 0.9764 - val_accuracy: 0.0000e+00 - val_loss: 1.4056\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5855 - loss: 0.9705 - val_accuracy: 0.0000e+00 - val_loss: 1.3709\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5888 - loss: 0.9706 - val_accuracy: 0.0000e+00 - val_loss: 1.4529\n",
      "Epoch 19/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5914 - loss: 0.9693 - val_accuracy: 0.0000e+00 - val_loss: 1.3945\n",
      "Epoch 20/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5929 - loss: 0.9660 - val_accuracy: 0.0000e+00 - val_loss: 1.3114\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5662 - loss: 0.9857 - val_accuracy: 0.0000e+00 - val_loss: 1.4488\n",
      "Epoch 22/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5746 - loss: 0.9802 - val_accuracy: 0.0000e+00 - val_loss: 1.4661\n",
      "Epoch 23/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5757 - loss: 0.9835 - val_accuracy: 0.0000e+00 - val_loss: 1.4075\n",
      "Epoch 24/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5715 - loss: 0.9804 - val_accuracy: 0.0000e+00 - val_loss: 1.4567\n",
      "Epoch 25/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5838 - loss: 0.9747 - val_accuracy: 0.0000e+00 - val_loss: 1.3460\n",
      "Epoch 26/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5625 - loss: 0.9860 - val_accuracy: 0.0000e+00 - val_loss: 1.4861\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5891 - loss: 0.9719 - val_accuracy: 0.0000e+00 - val_loss: 1.4016\n",
      "Epoch 28/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5824 - loss: 0.9747 - val_accuracy: 0.0000e+00 - val_loss: 1.3885\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5867 - loss: 0.9731 - val_accuracy: 0.0000e+00 - val_loss: 1.4308\n",
      "Epoch 30/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5981 - loss: 0.9622 - val_accuracy: 0.0000e+00 - val_loss: 1.3484\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5908 - loss: 0.9646 - val_accuracy: 0.0000e+00 - val_loss: 1.3799\n",
      "Epoch 32/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5879 - loss: 0.9685 - val_accuracy: 0.0000e+00 - val_loss: 1.4092\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5895 - loss: 0.9688 - val_accuracy: 0.0000e+00 - val_loss: 1.4032\n",
      "Epoch 34/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5936 - loss: 0.9674 - val_accuracy: 0.0000e+00 - val_loss: 1.3499\n",
      "Epoch 35/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6070 - loss: 0.9576 - val_accuracy: 0.0000e+00 - val_loss: 1.3261\n",
      "Epoch 36/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5870 - loss: 0.9703 - val_accuracy: 0.0000e+00 - val_loss: 1.4242\n",
      "Epoch 37/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5902 - loss: 0.9664 - val_accuracy: 0.0000e+00 - val_loss: 1.3746\n",
      "Epoch 38/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6017 - loss: 0.9599 - val_accuracy: 0.0000e+00 - val_loss: 1.3114\n",
      "Epoch 39/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5886 - loss: 0.9646 - val_accuracy: 0.0000e+00 - val_loss: 1.1398\n",
      "Epoch 40/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5954 - loss: 0.8804 - val_accuracy: 0.0000e+00 - val_loss: 0.7317\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5858 - loss: 0.8312 - val_accuracy: 0.0000e+00 - val_loss: 1.3886\n",
      "Epoch 42/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6002 - loss: 0.8233 - val_accuracy: 0.0000e+00 - val_loss: 1.6439\n",
      "Epoch 43/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6189 - loss: 0.7918 - val_accuracy: 0.5060 - val_loss: 0.4631\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5706 - loss: 0.9572 - val_accuracy: 0.0539 - val_loss: 0.6323\n",
      "Epoch 45/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6118 - loss: 0.7551 - val_accuracy: 0.0509 - val_loss: 0.6835\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6134 - loss: 0.7817 - val_accuracy: 0.0599 - val_loss: 0.9629\n",
      "Epoch 47/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6300 - loss: 0.7489 - val_accuracy: 0.1617 - val_loss: 1.0222\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6592 - loss: 0.7248 - val_accuracy: 0.3533 - val_loss: 0.6046\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6571 - loss: 0.7440 - val_accuracy: 0.1527 - val_loss: 1.2004\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6330 - loss: 0.7988 - val_accuracy: 0.2066 - val_loss: 0.7730\n",
      "Epoch 51/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6595 - loss: 0.6968 - val_accuracy: 0.3982 - val_loss: 0.8086\n",
      "Epoch 52/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7077 - loss: 0.7006 - val_accuracy: 0.1048 - val_loss: 1.2323\n",
      "Epoch 53/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6570 - loss: 0.7170 - val_accuracy: 0.4850 - val_loss: 0.6808\n",
      "Epoch 54/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7070 - loss: 0.6748 - val_accuracy: 0.1587 - val_loss: 1.0652\n",
      "Epoch 55/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6834 - loss: 0.6807 - val_accuracy: 0.2006 - val_loss: 1.0472\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6823 - loss: 0.6979 - val_accuracy: 0.3832 - val_loss: 0.8025\n",
      "Epoch 57/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7169 - loss: 0.6523 - val_accuracy: 0.3922 - val_loss: 0.8241\n",
      "Epoch 58/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7230 - loss: 0.6542 - val_accuracy: 0.6287 - val_loss: 0.4135\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7175 - loss: 0.6651 - val_accuracy: 0.3892 - val_loss: 0.8533\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7117 - loss: 0.6397 - val_accuracy: 0.5629 - val_loss: 0.5681\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7452 - loss: 0.6080 - val_accuracy: 0.5509 - val_loss: 0.5233\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7145 - loss: 0.6252 - val_accuracy: 0.7036 - val_loss: 0.3625\n",
      "Epoch 63/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7175 - loss: 0.6551 - val_accuracy: 0.6617 - val_loss: 0.4680\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7293 - loss: 0.6214 - val_accuracy: 0.6228 - val_loss: 0.4619\n",
      "Epoch 65/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7331 - loss: 0.5746 - val_accuracy: 0.7365 - val_loss: 0.3316\n",
      "Epoch 66/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7389 - loss: 0.6202 - val_accuracy: 0.5719 - val_loss: 0.4132\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7152 - loss: 0.6037 - val_accuracy: 0.3982 - val_loss: 0.7496\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7374 - loss: 0.6045 - val_accuracy: 0.6407 - val_loss: 0.4877\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.5731 - val_accuracy: 0.6198 - val_loss: 0.4553\n",
      "Epoch 70/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7561 - loss: 0.5672 - val_accuracy: 0.6317 - val_loss: 0.4800\n",
      "Epoch 71/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7398 - loss: 0.5862 - val_accuracy: 0.6647 - val_loss: 0.4718\n",
      "Epoch 72/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7522 - loss: 0.5621 - val_accuracy: 0.6916 - val_loss: 0.4221\n",
      "Epoch 73/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7651 - loss: 0.5347 - val_accuracy: 0.6647 - val_loss: 0.4073\n",
      "Epoch 74/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7411 - loss: 0.5610 - val_accuracy: 0.6766 - val_loss: 0.4241\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7725 - loss: 0.5248 - val_accuracy: 0.8443 - val_loss: 0.2087\n",
      "Epoch 76/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7808 - loss: 0.5464 - val_accuracy: 0.6557 - val_loss: 0.4849\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7776 - loss: 0.5134 - val_accuracy: 0.7575 - val_loss: 0.2965\n",
      "Epoch 78/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7720 - loss: 0.5197 - val_accuracy: 0.5359 - val_loss: 0.5544\n",
      "Epoch 79/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7696 - loss: 0.4935 - val_accuracy: 0.8144 - val_loss: 0.2776\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7970 - loss: 0.4659 - val_accuracy: 0.7725 - val_loss: 0.3612\n",
      "Epoch 81/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 0.4997 - val_accuracy: 0.7036 - val_loss: 0.4395\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7690 - loss: 0.4671 - val_accuracy: 0.3952 - val_loss: 0.6107\n",
      "Epoch 83/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7539 - loss: 0.4761 - val_accuracy: 0.8293 - val_loss: 0.2828\n",
      "Epoch 84/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8196 - loss: 0.4654 - val_accuracy: 0.6228 - val_loss: 0.4154\n",
      "Epoch 85/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7974 - loss: 0.4275 - val_accuracy: 0.7754 - val_loss: 0.2858\n",
      "Epoch 86/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8187 - loss: 0.4207 - val_accuracy: 0.7216 - val_loss: 0.3888\n",
      "Epoch 87/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8191 - loss: 0.4222 - val_accuracy: 0.8623 - val_loss: 0.2326\n",
      "Epoch 88/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8324 - loss: 0.4217 - val_accuracy: 0.6437 - val_loss: 0.4413\n",
      "Epoch 89/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7577 - loss: 0.5280 - val_accuracy: 0.8174 - val_loss: 0.2827\n",
      "Epoch 90/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8279 - loss: 0.4046 - val_accuracy: 0.8713 - val_loss: 0.2174\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8156 - loss: 0.4536 - val_accuracy: 0.9042 - val_loss: 0.1745\n",
      "Epoch 92/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8206 - loss: 0.4548 - val_accuracy: 0.7934 - val_loss: 0.3146\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8417 - loss: 0.3663 - val_accuracy: 0.8892 - val_loss: 0.1629\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8218 - loss: 0.4308 - val_accuracy: 0.7605 - val_loss: 0.3642\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8322 - loss: 0.4190 - val_accuracy: 0.8503 - val_loss: 0.2493\n",
      "Epoch 96/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8502 - loss: 0.4010 - val_accuracy: 0.7754 - val_loss: 0.3451\n",
      "Epoch 97/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8295 - loss: 0.4006 - val_accuracy: 0.8563 - val_loss: 0.2249\n",
      "Epoch 98/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8429 - loss: 0.4066 - val_accuracy: 0.8772 - val_loss: 0.2112\n",
      "Epoch 99/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8360 - loss: 0.4192 - val_accuracy: 0.7904 - val_loss: 0.3373\n",
      "Epoch 100/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8480 - loss: 0.3524 - val_accuracy: 0.8054 - val_loss: 0.2908\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8431 - loss: 0.3764 - val_accuracy: 0.8473 - val_loss: 0.2457\n",
      "Epoch 102/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8498 - loss: 0.3411 - val_accuracy: 0.7305 - val_loss: 0.3537\n",
      "Epoch 103/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8508 - loss: 0.3364 - val_accuracy: 0.7156 - val_loss: 0.4064\n",
      "Epoch 104/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8132 - loss: 0.3751 - val_accuracy: 0.8952 - val_loss: 0.1994\n",
      "Epoch 105/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8682 - loss: 0.3382 - val_accuracy: 0.7784 - val_loss: 0.2804\n",
      "Epoch 106/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8645 - loss: 0.3200 - val_accuracy: 0.8114 - val_loss: 0.2865\n",
      "Epoch 107/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8550 - loss: 0.3453 - val_accuracy: 0.8383 - val_loss: 0.2506\n",
      "Epoch 108/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8679 - loss: 0.3354 - val_accuracy: 0.8443 - val_loss: 0.2343\n",
      "Epoch 109/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8759 - loss: 0.3272 - val_accuracy: 0.8503 - val_loss: 0.2214\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8769 - loss: 0.2949 - val_accuracy: 0.9072 - val_loss: 0.1514\n",
      "Epoch 111/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8815 - loss: 0.3229 - val_accuracy: 0.8234 - val_loss: 0.2380\n",
      "Epoch 112/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8485 - loss: 0.3494 - val_accuracy: 0.8832 - val_loss: 0.1899\n",
      "Epoch 113/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8783 - loss: 0.3068 - val_accuracy: 0.8892 - val_loss: 0.1733\n",
      "Epoch 114/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8799 - loss: 0.3126 - val_accuracy: 0.8743 - val_loss: 0.2219\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8846 - loss: 0.2943 - val_accuracy: 0.8293 - val_loss: 0.2501\n",
      "Epoch 116/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8442 - loss: 0.3734 - val_accuracy: 0.8443 - val_loss: 0.2506\n",
      "Epoch 117/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8520 - loss: 0.3355 - val_accuracy: 0.8922 - val_loss: 0.1749\n",
      "Epoch 118/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8720 - loss: 0.3165 - val_accuracy: 0.8832 - val_loss: 0.1914\n",
      "Epoch 119/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8300 - loss: 0.4611 - val_accuracy: 0.8593 - val_loss: 0.2169\n",
      "Epoch 120/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8152 - loss: 0.4151 - val_accuracy: 0.9132 - val_loss: 0.1585\n",
      "Epoch 121/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8900 - loss: 0.2840 - val_accuracy: 0.8683 - val_loss: 0.1905\n",
      "Epoch 122/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8855 - loss: 0.2830 - val_accuracy: 0.8503 - val_loss: 0.2060\n",
      "Epoch 123/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8950 - loss: 0.2770 - val_accuracy: 0.8443 - val_loss: 0.2265\n",
      "Epoch 124/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9003 - loss: 0.2639 - val_accuracy: 0.7844 - val_loss: 0.3093\n",
      "Epoch 125/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8477 - loss: 0.3420 - val_accuracy: 0.8922 - val_loss: 0.1999\n",
      "Epoch 126/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8679 - loss: 0.3807 - val_accuracy: 0.9132 - val_loss: 0.1597\n",
      "Epoch 127/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8974 - loss: 0.2517 - val_accuracy: 0.8772 - val_loss: 0.2072\n",
      "Epoch 128/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9149 - loss: 0.2394 - val_accuracy: 0.8862 - val_loss: 0.2030\n",
      "Epoch 129/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8994 - loss: 0.2491 - val_accuracy: 0.8503 - val_loss: 0.2378\n",
      "Epoch 130/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9016 - loss: 0.2478 - val_accuracy: 0.8892 - val_loss: 0.1861\n",
      "Epoch 131/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9048 - loss: 0.2546 - val_accuracy: 0.8293 - val_loss: 0.2990\n",
      "Epoch 132/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9048 - loss: 0.2382 - val_accuracy: 0.8892 - val_loss: 0.1857\n",
      "Epoch 133/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8669 - loss: 0.3704 - val_accuracy: 0.8743 - val_loss: 0.1944\n",
      "Epoch 134/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8935 - loss: 0.2781 - val_accuracy: 0.8503 - val_loss: 0.2228\n",
      "Epoch 135/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9028 - loss: 0.2264 - val_accuracy: 0.8802 - val_loss: 0.1995\n",
      "Epoch 136/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9235 - loss: 0.1915 - val_accuracy: 0.8802 - val_loss: 0.1703\n",
      "Epoch 137/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9079 - loss: 0.2273 - val_accuracy: 0.8772 - val_loss: 0.1933\n",
      "Epoch 138/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9072 - loss: 0.2536 - val_accuracy: 0.9102 - val_loss: 0.1615\n",
      "Epoch 139/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9382 - loss: 0.1743 - val_accuracy: 0.8503 - val_loss: 0.1919\n",
      "Epoch 140/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9049 - loss: 0.2570 - val_accuracy: 0.8713 - val_loss: 0.2109\n",
      "Epoch 141/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9249 - loss: 0.1843 - val_accuracy: 0.9072 - val_loss: 0.1611\n",
      "Epoch 142/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9306 - loss: 0.1937 - val_accuracy: 0.9102 - val_loss: 0.1649\n",
      "Epoch 143/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9274 - loss: 0.2038 - val_accuracy: 0.8952 - val_loss: 0.1671\n",
      "Epoch 144/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9100 - loss: 0.2098 - val_accuracy: 0.8263 - val_loss: 0.3062\n",
      "Epoch 145/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9305 - loss: 0.1873 - val_accuracy: 0.9012 - val_loss: 0.1974\n",
      "Epoch 146/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9335 - loss: 0.1846 - val_accuracy: 0.9132 - val_loss: 0.1585\n",
      "Epoch 147/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9412 - loss: 0.1832 - val_accuracy: 0.8503 - val_loss: 0.2515\n",
      "Epoch 148/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9247 - loss: 0.1881 - val_accuracy: 0.9251 - val_loss: 0.1383\n",
      "Epoch 149/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9352 - loss: 0.1873 - val_accuracy: 0.9012 - val_loss: 0.1925\n",
      "Epoch 150/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9261 - loss: 0.1742 - val_accuracy: 0.8802 - val_loss: 0.2271\n",
      "Epoch 151/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9165 - loss: 0.1917 - val_accuracy: 0.9192 - val_loss: 0.1602\n",
      "Epoch 152/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9288 - loss: 0.1724 - val_accuracy: 0.8802 - val_loss: 0.1914\n",
      "Epoch 153/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9411 - loss: 0.1465 - val_accuracy: 0.9132 - val_loss: 0.1705\n",
      "Epoch 154/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9513 - loss: 0.1468 - val_accuracy: 0.8713 - val_loss: 0.2062\n",
      "Epoch 155/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9321 - loss: 0.1548 - val_accuracy: 0.9162 - val_loss: 0.1675\n",
      "Epoch 156/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9472 - loss: 0.1341 - val_accuracy: 0.8952 - val_loss: 0.1919\n",
      "Epoch 157/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9478 - loss: 0.1358 - val_accuracy: 0.8982 - val_loss: 0.1997\n",
      "Epoch 158/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9444 - loss: 0.1394 - val_accuracy: 0.9042 - val_loss: 0.1585\n",
      "Epoch 159/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9525 - loss: 0.1219 - val_accuracy: 0.8772 - val_loss: 0.2400\n",
      "Epoch 160/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9187 - loss: 0.2149 - val_accuracy: 0.9102 - val_loss: 0.1933\n",
      "Epoch 161/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9504 - loss: 0.1371 - val_accuracy: 0.9072 - val_loss: 0.1735\n",
      "Epoch 162/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9511 - loss: 0.1289 - val_accuracy: 0.9281 - val_loss: 0.1364\n",
      "Epoch 163/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9370 - loss: 0.1777 - val_accuracy: 0.8892 - val_loss: 0.1757\n",
      "Epoch 164/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9095 - loss: 0.2266 - val_accuracy: 0.9012 - val_loss: 0.1773\n",
      "Epoch 165/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9322 - loss: 0.1691 - val_accuracy: 0.9042 - val_loss: 0.1974\n",
      "Epoch 166/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9632 - loss: 0.1081 - val_accuracy: 0.9222 - val_loss: 0.1400\n",
      "Epoch 167/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9328 - loss: 0.1676 - val_accuracy: 0.9162 - val_loss: 0.1464\n",
      "Epoch 168/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9535 - loss: 0.1126 - val_accuracy: 0.9311 - val_loss: 0.1440\n",
      "Epoch 169/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9524 - loss: 0.1393 - val_accuracy: 0.8743 - val_loss: 0.2781\n",
      "Epoch 170/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9468 - loss: 0.1444 - val_accuracy: 0.9251 - val_loss: 0.1603\n",
      "Epoch 171/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9610 - loss: 0.1102 - val_accuracy: 0.8982 - val_loss: 0.2032\n",
      "Epoch 172/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9469 - loss: 0.1460 - val_accuracy: 0.8982 - val_loss: 0.1949\n",
      "Epoch 173/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9546 - loss: 0.1354 - val_accuracy: 0.9042 - val_loss: 0.1993\n",
      "Epoch 174/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9595 - loss: 0.1025 - val_accuracy: 0.8982 - val_loss: 0.1758\n",
      "Epoch 175/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9473 - loss: 0.1473 - val_accuracy: 0.9012 - val_loss: 0.2010\n",
      "Epoch 176/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9632 - loss: 0.0989 - val_accuracy: 0.9251 - val_loss: 0.1831\n",
      "Epoch 177/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9599 - loss: 0.1046 - val_accuracy: 0.7874 - val_loss: 0.5048\n",
      "Epoch 178/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8691 - loss: 0.4138 - val_accuracy: 0.8593 - val_loss: 0.2682\n",
      "Epoch 179/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9033 - loss: 0.2101 - val_accuracy: 0.8922 - val_loss: 0.2118\n",
      "Epoch 180/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9589 - loss: 0.1047 - val_accuracy: 0.9132 - val_loss: 0.1941\n",
      "Epoch 181/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9501 - loss: 0.1116 - val_accuracy: 0.8802 - val_loss: 0.2730\n",
      "Epoch 182/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9622 - loss: 0.0988 - val_accuracy: 0.9251 - val_loss: 0.1625\n",
      "Epoch 183/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9672 - loss: 0.0994 - val_accuracy: 0.9251 - val_loss: 0.1921\n",
      "Epoch 184/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9732 - loss: 0.0712 - val_accuracy: 0.9162 - val_loss: 0.1752\n",
      "Epoch 185/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9733 - loss: 0.0890 - val_accuracy: 0.9341 - val_loss: 0.1627\n",
      "Epoch 186/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9779 - loss: 0.0798 - val_accuracy: 0.9311 - val_loss: 0.1664\n",
      "Epoch 187/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9736 - loss: 0.0759 - val_accuracy: 0.9222 - val_loss: 0.1901\n",
      "Epoch 188/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9642 - loss: 0.1192 - val_accuracy: 0.9162 - val_loss: 0.1768\n",
      "Epoch 189/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9637 - loss: 0.1114 - val_accuracy: 0.9192 - val_loss: 0.1654\n",
      "Epoch 190/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9657 - loss: 0.0899 - val_accuracy: 0.9311 - val_loss: 0.1517\n",
      "Epoch 191/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9698 - loss: 0.0750 - val_accuracy: 0.9222 - val_loss: 0.2078\n",
      "Epoch 192/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9695 - loss: 0.0847 - val_accuracy: 0.9311 - val_loss: 0.1506\n",
      "Epoch 193/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9756 - loss: 0.0671 - val_accuracy: 0.9371 - val_loss: 0.1721\n",
      "Epoch 194/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9724 - loss: 0.0678 - val_accuracy: 0.9311 - val_loss: 0.1572\n",
      "Epoch 195/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9279 - loss: 0.2089 - val_accuracy: 0.9341 - val_loss: 0.1734\n",
      "Epoch 196/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9640 - loss: 0.1114 - val_accuracy: 0.8743 - val_loss: 0.2563\n",
      "Epoch 197/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9608 - loss: 0.1030 - val_accuracy: 0.9072 - val_loss: 0.2109\n",
      "Epoch 198/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9278 - loss: 0.2067 - val_accuracy: 0.9281 - val_loss: 0.1439\n",
      "Epoch 199/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9215 - loss: 0.2863 - val_accuracy: 0.9222 - val_loss: 0.1619\n",
      "Epoch 200/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9520 - loss: 0.1202 - val_accuracy: 0.9251 - val_loss: 0.1725\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_gru,\n",
    "    y_train_resampled,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.8541 \n",
      "Test Loss: 0.8833\n",
      "Test Accuracy: 0.7814\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_gru, y_test_encoded)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "def predict_classes(model, X):\n",
    "    X_reshaped = prepare_data_for_gru(X)\n",
    "    raw_predictions = model.predict(X_reshaped)\n",
    "    predictions = np.sign(raw_predictions)\n",
    "    return (predictions + 1) / 2\n",
    "\n",
    "y_pred = predict_classes(model, X_test_processed)\n",
    "\n",
    "classes_x2 = y_pred.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          label neg   label pos\n",
      "pred neg     235          48\n",
      "pred pos     42          105\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.6862745098039216\n",
      "F1: 0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(classes_x2)):\n",
    "  if classes_x2[i] == 1:\n",
    "    if y_test_encoded[i] == 1:\n",
    "      TP = TP + 1\n",
    "    else :\n",
    "      FP = FP + 1\n",
    "  else:\n",
    "    if y_test_encoded[i] == 0:\n",
    "      TN = TN + 1\n",
    "    else :\n",
    "      FN = FN + 1\n",
    "\n",
    "\n",
    "print('         ', 'label neg ', ' label pos')\n",
    "print('pred neg    ', TN, \"        \", FN)\n",
    "print('pred pos    ', FP, \"        \", TP)\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2*precision*recall / (precision + recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9 | packaged by conda-forge | (main, Mar  4 2025, 22:44:42) [Clang 18.1.8 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f8dd9a2b65164a0dd37b4e5739f150314b1e17efbbfa1422ea4f2e7b18b306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
